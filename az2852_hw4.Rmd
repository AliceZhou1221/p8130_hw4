---
title: "az2852_hw4"
output: pdf_document
---

```{r}
library(tidyverse)
library(BSDA)
```

# Problem 1 (10 points)

A new device has been developed which allows patients to evaluate their blood sugar levels.  The most widely device currently on the market yields widely variable results. The new device is evaluated by 25 patients having nearly the same distribution of blood sugar levels yielding the following data:

125 123 117 123 115 112 128 118 124
111 116 109 125 120 113 123 112 118
121 118 122 115 105 118 131

a) Is there significant ($\alpha = 0.05$) evidence that median blood sugar readings was less than 120 in the population from which the 25 patients were selected?  Use the sign test and report the test statistic and p-value.

H0: The median blood sugar level is equal to 120.
H1: The median blood sugar level is less than 120.
```{r}
data = c(125, 123, 117, 123, 115, 112, 128, 118, 124,
          111, 116, 109, 125, 120, 113, 123, 112, 118,
          121, 118, 122, 115, 105, 118, 131)

SIGN.test(data, md = 120, alternative = "less")
```
The number of negative differences s = 10, p-value = 0.2706, larger than 0.05, so we fail to reject the null hypothesis.We don't have enough evidence that median population blood sugar readings is less than 120.

b) Is there significant ($\alpha = 0.05$) evidence that median blood sugar readings was less than 120 in the population from which the 25 patients were selected?  Use the Wilcoxon signed-rank test and report the test statistic and p-value.

H0: The median blood sugar level is equal to 120.
H1: The median blood sugar level is less than 120.
```{r}
wilcox.test(data, mu = 120, alternative = "less", exact = FALSE)
```
The sum of negative ranks V = 112.5, p-value = 0.1447, larger than 0.05, so we fail to reject the null hypothesis.We don't have enough evidence that median population blood sugar readings is less than 120.

# Problem 2 (15 points)

Human brains have a large frontal cortex with excessive metabolic demands compared with the brains of other primates. However, the human brain is also three or more times the size of the brains of other primates. Is it possible that the metabolic demands of the human frontal cortex are just an expected consequence of greater brain size? A data file containing the measurements of glia-neuron ratio (an indirect measure of the metabolic requirements of brain neurons) and the log-transformed brain mass in nonhuman primates was provided to you along with the following graph.

```{r}
#| echo: false
#| message: false
#| fig.width: 2.5
#| fig.height: 2
#| fig.align: "center"
#| fig.pos: "h"

library(tidyverse)

brain = readxl::read_xlsx("Brain.xlsx")

brain %>% 
  slice(-1) %>% 
  ggplot(aes(x = `Ln Brain mass`, y = `Glia-neuron ratio`)) +
  geom_smooth(method = "lm", se = FALSE, color = "black") +
  geom_point(color = "red") +
  geom_point(aes(x = brain$`Ln Brain mass`[1], 
                 y = brain$`Glia-neuron ratio`[1])) +
  guides(color = "none") +
  theme_classic()
```

a) Fit a regression model for the nonhuman data using $\ln{(\textrm{brain mass})}$ as a predictor.  (Hint: Humans are "homo sapiens".)
```{r}
# Filter out humans
nonhuman_data = subset(brain, Species != "Homo sapiens")

model = lm(`Glia-neuron ratio` ~ `Ln Brain mass`, data = nonhuman_data)

summary(model)
```

b) Using the nonhuman primate relationship, what is the predicted glia-neuron ratio for humans, given their brain mass?

```{r}
human_lnBrainMass = brain %>% 
  filter(Species == "Homo sapiens") %>% 
  pull(`Ln Brain mass`)

predict(model, newdata = tibble(`Ln Brain mass` = human_lnBrainMass))
```
The predicted glia-neuron ratio for humans is 1.471.

c) Determine the most plausible range of values for the prediction.  Which is more relevant for your prediction of human glia-neuron ratio: an interval for the predicted mean glia-neuron ratio at the given brain mass, or an interval for the prediction of a single new observation?

The prediction interval is more relevant because it accounts for the
uncertainty in predicting a single data point.

d) Construct the 95% interval chosen in part (c).  On the basis of your result, does the human brain have an excessive glia-neuron ratio for its mass compared with other primates?
construct a 95% PI:
```{r}
predict(model, newdata = tibble(`Ln Brain mass` = human_lnBrainMass), interval = "prediction", level = 0.95)
```
The 95% PI for the average human glia-neuron ratio is [1.036047, 1.906869].

The observed value is 1.65, inside the CI. We do not have enough evidence to suggest that the human brain has an excessive glia-neuron ratio for its mass compared with other primates

e) Considering the position of the human data point relative to those data used to generate the regression line (see graph above), what additional caution is warranted?

Considering that the human data point lies far above the regression line, it might be an outlier that can't be appropriately estimated with our regression model. The deviation of the human data point suggests that additional factors, beyond brain mass alone, may need to be considered when predicting human brain glia-neuron ratio.

# Problem 3 (25 points)

For this problem, you will be using data `HeartDisease.csv`. The investigator is mainly interested if there is an association between ‘total cost’ (in dollars) of patients diagnosed with heart disease and the ‘number of emergency room (ER) visits’. Further, the model will need to be adjusted for other factors, including ‘age’, ‘gender’, ‘number of complications’ that arose during treatment, and ‘duration of treatment condition’.

a) Provide a short description of the data set: what is the main outcome, main predictor and other important covariates. Also, generate appropriate descriptive statistics for all variables of interest (continuous and categorical) – no test required.
```{r}
#load the data
heart_df = read_csv("HeartDisease.csv")
```
The main outcome is `totalcost` (total cost of claims by the subscriber in dollars), the main predictor is `ERvisits` (number of ER visits). 

Other important covariates include `age`, `gender`(1 for male, 0 for female), `interventions`(total number of interventions or procedures), `drugs`(Number of drugs prescribed), `complications`(Number of complications during treatment), `comorbidities`(Number of other diseases the patient had), and `duration`(Duration of treatment in days).

Descriptive statistics:
```{r}
summary(heart_df)
```

b) Investigate the shape of the distribution for variable `totalcost` and try different transformations, if needed.

The distribution is severely right skewed. We will use a log transformation.
```{r}
ggplot(heart_df, aes(x = totalcost))+
  geom_histogram()
```
```{r}
# Apply log transformation to 'totalcost'
heart_df$totalcost_log = log(heart_df$totalcost + 1)  # +1 to handle zero values

# Visualize the transformed distribution
ggplot(heart_df, aes(x = totalcost_log)) +
  geom_histogram(binwidth = 0.1, fill = "skyblue", color = "black") +
  theme_minimal() +
  labs(title = "Log-Transformed Distribution of Total Cost", x = "Log of Total Cost", y = "Frequency")

# Calculate basic statistics for the log-transformed variable
summary(heart_df$totalcost_log)
```

c) Create a new variable called `comp_bin` by dichotomizing ‘complications’: 0 if no complications, and 1 otherwise.
```{r}
heart_df = heart_df %>% 
  mutate(comp_bin = ifelse(heart_df$complications == 0, 0, 1))
```


d) Based on your decision in part (b), fit a simple linear regression (SLR) between the original or transformed `totalcost` and predictor `ERvisits`. This includes a scatterplot and results of the regression, with appropriate comments on significance and interpretation of the slope.

The p values is  <2e-16, indicating that the relationship between number of ER visits and total cost is strongly statistically significant. 

The slope is 0.22529, suggesting a positive linear relationship between totalcost and ERvists. For each additional ER visit, the log of total cost increases by 0.22529.
```{r}
# Fit a simple linear regression model with log-transformed totalcost and ERvisits
model_simple = lm(totalcost_log ~ ERvisits, data = heart_df)

# Summary of the regression model
summary(model_simple)

# Scatterplot with regression line for log-transformed totalcost
ggplot(heart_df, aes(x = ERvisits, y = totalcost_log)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  theme_minimal() +
  labs(title = "Scatterplot of ERvisits vs Log of Total Cost", x = "ER Visits", y = "Log of Total Cost")
```


e) Fit a multiple linear regression (MLR) with `comp_bin` and `ERvisits` as predictors.
```{r}
# Fit the MLR model for log transformed total cost with 'ERvisits', and 'comp_bin' as predictors
model_mlr = lm(totalcost_log ~ ERvisits + comp_bin, data = heart_df)

# Summary of the model
summary(model_mlr)
```

    i) Test if `comp_bin` is an effect modifier of the relationship between `totalcost` and `ERvisits`. Comment.
The p-value for the interaction term is 0.311, larger than 0.05. We conclude that comp_bin does not modify the relationship between ERvisits and totalcost_log.
```{r}
# Fit the model with interaction term between 'ERvisits' and 'comp_bin'
model_interaction = lm(totalcost_log ~ ERvisits * comp_bin, data = heart_df)

# Summary of the interaction model
summary(model_interaction)
```
    
    ii) Test if `comp_bin` is a confounder of the relationship between `totalcost` and `ERvisits`. Comment.
```{r}
# Extract coefficients for ERvisits from both models & calculate the difference
coef_simple = summary(model_simple)$coefficients["ERvisits", "Estimate"]
coef_mlr = summary(model_mlr)$coefficients["ERvisits", "Estimate"]

diff_coef = coef_mlr - coef_simple
diff_coef
```
The difference between the coefficients is `r diff_coef`. The difference is quite small, suggesting that comp_bin is not a confounder.     
    
    iii) Decide if `comp_bin` should be included along with `ERvisits`. Why or why not?
We don't need to include `comp-bin` when trying to understand the relationship between total cost and ERvisits as `comp_bin` is neither an effect modifier nor a confounder.

f) Use your choice of model in part (e) and add additional covariates (age, gender, and duration of treatment).

    i) Fit a MLR, show the regression results and comment.
```{r}
model_cov = lm(totalcost_log ~ ERvisits + comp_bin + age + gender + duration, data = heart_df)
summary(model_cov)
```

In this MLR, significant predictors are ERvisits, comp_bin, age, and duration of treatment, while gender does not appear to be a significant predictor. The coefficients suggest:

* `ERvisits`: The coefficient (0.175) is significant (p < 0.001),
indicating that ER visits have a positive association with
totalcost_log.  

* `Comp_bin`: The coefficient (1.504) is significant (p < 0.001),
suggesting that total cost increases when there are complications.  

* `Age`: The coefficient (-0.0206) is significant (p = 0.0175), showing a
small negative effect on log_totalcost.  

* `Gender`: Not significant (p = 0.1364).  

* `Duration`: The coefficient (0.005) is significant (p < 0.001), indicating a small positive effect.

    ii) Compare the SLR and MLR models. Which model would you use to address the investigator’s objective and why?

The MLR model has an R-squared of 0.269, much higher than the SLR
model’s 0.098. This indicates a better fit and more explained
variance.  
The MLR model is more preferable because it accounts for potential confounders in the covariates.