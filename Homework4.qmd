---
title: "Homework 4"
author: "P8130 Fall 2022"
date: "Due: November 13, 2022 at midnight Eastern"
format: pdf
---

### P8130 Guidelines for Submitting Homework

* Your homework must be submitted through Courseworks. No email submissions!

* Only one PDF file should be submitted, including all derivations, graphs, output, and interpretations. When handwriting is allowed (this will be specified), scan the derivations and merge ALL PDF files (http: //www.pdfmerge.com/).

* You are encouraged to use R for calculations, but you must show all mathematical formulas and derivations. Please include the important parts of your R code in the PDF file but also submit your full, commented code as a separate R/RMD file.

* To best follow these guidelines, we suggest using Word (built in equation editor), R Markdown, Latex, or embedding a screenshot or scanned picture to compile your work.

DO NOT FORGET: You are encouraged to collaborate on homeworks, explain things to each other, and test each other’s knowledge. But Do NOT hand out answers to someone who has not done any work. Everyone ought to have ideas about the possible answers or at least some thoughts about how to probe the problem further. Write your own solutions!

\newpage

```{r}
library(tidyverse)
library(BSDA)
```

# Problem 1 (10 points)

A new device has been developed which allows patients to evaluate their blood sugar levels.  The most widely device currently on the market yields widely variable results. The new device is evaluated by 25 patients having nearly the same distribution of blood sugar levels yielding the following data:

125 123 117 123 115 112 128 118 124
111 116 109 125 120 113 123 112 118
121 118 122 115 105 118 131

a) Is there significant ($\alpha = 0.05$) evidence that median blood sugar readings was less than 120 in the population from which the 25 patients were selected?  Use the sign test and report the test statistic and p-value.
H0: The median blood sugar level is equal to 120.
H1: The median blood sugar level is less than 120.
```{r}
data = c(125, 123, 117, 123, 115, 112, 128, 118, 124,
          111, 116, 109, 125, 120, 113, 123, 112, 118,
          121, 118, 122, 115, 105, 118, 131)

SIGN.test(data, md = 120, alternative = "less")
```
The number of negative differences s = 10, p-value = 0.2706, larger than 0.05, so we fail to reject the null hypothesis.We don't have enough evidence that median population blood sugar readings is less than 120.

b) Is there significant ($\alpha = 0.05$) evidence that median blood sugar readings was less than 120 in the population from which the 25 patients were selected?  Use the Wilcoxon signed-rank test and report the test statistic and p-value.
H0: The median blood sugar level is equal to 120.
H1: The median blood sugar level is less than 120.
```{r}
wilcox.test(data, mu = 120, alternative = "less", exact = FALSE)
```
The sum of negative ranks V = 112.5, p-value = 0.1447, larger than 0.05, so we fail to reject the null hypothesis.We don't have enough evidence that median population blood sugar readings is less than 120.

# Problem 2 (15 points)

Human brains have a large frontal cortex with excessive metabolic demands compared with the brains of other primates. However, the human brain is also three or more times the size of the brains of other primates. Is it possible that the metabolic demands of the human frontal cortex are just an expected consequence of greater brain size? A data file containing the measurements of glia-neuron ratio (an indirect measure of the metabolic requirements of brain neurons) and the log-transformed brain mass in nonhuman primates was provided to you along with the following graph.

```{r}
#| echo: false
#| message: false
#| fig.width: 2.5
#| fig.height: 2
#| fig.align: "center"
#| fig.pos: "h"

library(tidyverse)

brain = readxl::read_xlsx("Brain.xlsx")

brain %>% 
  slice(-1) %>% 
  ggplot(aes(x = `Ln Brain mass`, y = `Glia-neuron ratio`)) +
  geom_smooth(method = "lm", se = FALSE, color = "black") +
  geom_point(color = "red") +
  geom_point(aes(x = brain$`Ln Brain mass`[1], 
                 y = brain$`Glia-neuron ratio`[1])) +
  guides(color = "none") +
  theme_classic()
```

a) Fit a regression model for the nonhuman data using $\ln{(\textrm{brain mass})}$ as a predictor.  (Hint: Humans are "homo sapiens".)
```{r}
# Filter out humans
nonhuman_data = subset(brain, Species != "homo sapiens")

model = lm(`Glia-neuron ratio` ~ `Ln Brain mass`, data = nonhuman_data)

summary(model)
```

b) Using the nonhuman primate relationship, what is the predicted glia-neuron ratio for humans, given their brain mass?

```{r}
human_lnBrainMass = brain %>% 
  filter(Species == "Homo sapiens") %>% 
  pull(`Ln Brain mass`)

predict(model, newdata = tibble(`Ln Brain mass` = human_lnBrainMass))
```
The predicted glia-neuron ratio for humans is 1.53.

c) Determine the most plausible range of values for the prediction.  Which is more relevant for your prediction of human glia-neuron ratio: an interval for the predicted mean glia-neuron ratio at the given brain mass, or an interval for the prediction of a single new observation?

Since we are estimating the average glia-neuron ratio for humans, not the ratio for a specific new individual, the interval for the predicted mean is more appropriate.

d) Construct the 95% interval chosen in part (c).  On the basis of your result, does the human brain have an excessive glia-neuron ratio for its mass compared with other primates?
construct a 95% CI:
```{r}
predict(model, newdata = tibble(`Ln Brain mass` = human_lnBrainMass), interval = "confidence", level = 0.95)
```
The 95% CI for the average human glia-neuron ratio is [1.328004, 1.725128].

The observed value is 1.65, inside the CI. We do not have enough evidence to suggest that the human brain has an excessive glia-neuron ratio for its mass compared with other primates

e) Considering the position of the human data point relative to those data used to generate the regression line (see graph above), what additional caution is warranted?

Considering that the human data point lies far above the regression line, it might be an outlier that can't be appropriately estimated with our regression model. The deviation of the human data point suggests that additional factors, beyond brain mass alone, may need to be considered when predicting human brain glia-neuron ratio.

# Problem 3 (25 points)

For this problem, you will be using data `HeartDisease.csv`. The investigator is mainly interested if there is an association between ‘total cost’ (in dollars) of patients diagnosed with heart disease and the ‘number of emergency room (ER) visits’. Further, the model will need to be adjusted for other factors, including ‘age’, ‘gender’, ‘number of complications’ that arose during treatment, and ‘duration of treatment condition’.

a) Provide a short description of the data set: what is the main outcome, main predictor and other important covariates. Also, generate appropriate descriptive statistics for all variables of interest (continuous and categorical) – no test required.
```{r}
#load the data
heart_df = read_csv("HeartDisease.csv")
```
The main outcome is `totalcost`, the main predictor is `ERvisits`. Other important covariates include `age`, `gender`, `interventions`, `drugs`, `complications`, `comorbidities`, and `duration`.
Descriptive statistics:
```{r}
summary(heart_df)
```

b) Investigate the shape of the distribution for variable `totalcost` and try different transformations, if needed.

The distribution is severely right skewed.
```{r}
ggplot(heart_df, aes(x = totalcost))+
  geom_histogram()
```
```{r}
# Apply log transformation to 'totalcost'
heart_df$totalcost_log = log(heart_df$totalcost + 1)  # +1 to handle zero values

# Visualize the transformed distribution
ggplot(heart_df, aes(x = totalcost_log)) +
  geom_histogram(binwidth = 0.1, fill = "skyblue", color = "black") +
  theme_minimal() +
  labs(title = "Log-Transformed Distribution of Total Cost", x = "Log of Total Cost", y = "Frequency")

# Calculate basic statistics for the log-transformed variable
summary(heart_df$totalcost_log)
```


c) Create a new variable called `comp_bin` by dichotomizing ‘complications’: 0 if no complications, and 1 otherwise.
```{r}
heart_df = heart_df %>% 
  mutate(comp_bin = ifelse(heart_df$complications == 0, 0, 1))
```


d) Based on your decision in part (b), fit a simple linear regression (SLR) between the original or transformed `totalcost` and predictor `ERvisits`. This includes a scatterplot and results of the regression, with appropriate comments on significance and interpretation of the slope.
The slope is 0.22529, suggesting a positive linear relationship between totalcost and ERvists. For each additional ER visit, the log of total cost increases by 0.22529. The p values is near 0, indicating that the relationship is statistically significant. 
```{r}
# Fit a simple linear regression model with log-transformed totalcost and ERvisits
model_log = lm(totalcost_log ~ ERvisits, data = heart_df)

# Summary of the regression model
summary(model_log)

# Scatterplot with regression line for log-transformed totalcost
ggplot(heart_df, aes(x = ERvisits, y = totalcost_log)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  theme_minimal() +
  labs(title = "Scatterplot of ERvisits vs Log of Total Cost", x = "ER Visits", y = "Log of Total Cost")
```


e) Fit a multiple linear regression (MLR) with `comp_bin` and `ERvisits` as predictors.
```{r}
# Fit the MLR model for log transformed total cost with 'ERvisits', and 'comp_bin' as predictors
model_mlr = lm(totalcost_log ~ ERvisits + comp_bin, data = heart_df)

# Summary of the model
summary(model_mlr)
```

    i) Test if `comp_bin` is an effect modifier of the relationship between `totalcost` and `ERvisits`. Comment.
    The p-value for the interaction term is 0.311, larger than 0.05. We conclude that comp_bin does not modify the relationship between ERvisits and totalcost_log.
```{r}
# Fit the model with interaction term between 'ERvisits' and 'comp_bin'
model_interaction = lm(totalcost_log ~ ERvisits * comp_bin, data = heart_df)

# Summary of the interaction model
summary(model_interaction)
```
    
    ii) Test if `comp_bin` is a confounder of the relationship between `totalcost` and `ERvisits`. Comment.
    
```{r}
# Simple linear regression (Model without comp_bin)
model_simple = lm(totalcost_log ~ ERvisits, data = heart_df)

# Summary of the model
summary(model_simple)

# Multiple regression with comp_bin
model_confounder = lm(totalcost_log ~ ERvisits + comp_bin, data = heart_df)

# Summary of the model
summary(model_confounder)

# Extract coefficients for ERvisits from both models & calculate the difference
coef_simple = summary(model_simple)$coefficients["ERvisits", "Estimate"]
coef_confounder = summary(model_confounder)$coefficients["ERvisits", "Estimate"]

diff_coef = coef_confounder - coef_simple
diff_coef
```
 The difference between the coefficients is `r diff_coef`. The difference is quite small, suggesting that comp_bin is not a confounder.     
    
    iii) Decide if `comp_bin` should be included along with `ERvisits`. Why or why not?
    We don't need to include `comp-bin` when trying to understand the relationship between total cost and ERvisits as `comp_bin` is neither an effect modifier nor a confounder.

f) Use your choice of model in part (e) and add additional covariates (age, gender, and duration of treatment).

    i) Fit a MLR, show the regression results and comment.
```{r}
model_cov = lm(totalcost_log ~ ERvisits + comp_bin + age + gender + duration, data = heart_df)
summary(model_cov)
```

In this MLR, significant predictors are ERvisits, comp_bin, age, and duration of treatment, while gender does not appear to be a significant predictor. The coefficients suggest:

* total cost increases as number of ER visits increases
* total cost increases as treatment duration increases
* total cost increases when there are complications
* total cost increases as age increases.
    
    ii) Compare the SLR and MLR models. Which model would you use to address the investigator’s objective and why?
    The MLR model is more preferable because it accounts for potential confounders and effect modifiers in the covariates. In contrast, the SLR model is limited in scope and may lead to biased estimates due to confounding.